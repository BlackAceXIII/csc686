{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Algorithmic and Search Complexity\n",
    "\n",
    "_course: the real blockchain\n",
    "<br>date: 2 september 2020\n",
    "<br>update: 3 september 2020\n",
    "<br>author: burton rosenberg_\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "Security is a matter of chance. In most instances of securing a device, whether it be a password, a physical\n",
    "key, or even a safe, since there is some valid way to open the secured device, a determined attacker can open the secured device. This can either be by,\n",
    "\n",
    "\n",
    "- a methodical search, of one key after the other,\n",
    "- randomly guessing the key, \n",
    "- calculating the key given a weakness in the system.\n",
    "\n",
    "It is important if the system is secure that the first two options be slow in a very meaningful way, and that the thir way does not exist.\n",
    "\n",
    "Facing a methodical search, we want that the serach be exponentially lengthy in the size of the key. There are 26^10 different passwords on ten letters. The good guy only needs to recite ten letters, the bad guy needs to search (on average) 26^10/2 possibilities.\n",
    "\n",
    "Facing a random guess, we want that the probability of guessing correctly is exponentially small in the size of the key. In the case of our 10 letter password, the attacker's probability of guessing the key (in one try, assuming a \"good\" key) is miniscule: 1/26^10.\n",
    "\n",
    "Facing a weakness in the system, we will suppose that a computer algorithm exploits the weakness (so we are not talking about _social engineering_ or other attacks, just \"laboratory conditions\") is sufficently inefficient as to not be an improvement on the first attack &mdash; methodical search.\n",
    "\n",
    "\n",
    "## Algorithm Complexity\n",
    "\n",
    "We explore first the theory supporting the last case.\n",
    "\n",
    "We have to measure the run time of the algorithm, similar to how we measure methodical search by counting something and making a broad statement that that count is a sufficient indication of run time. In methodical \n",
    "search we count key tries, and assume each key try takes a fixed amount of time. More might need be done \n",
    "than try the key, but we are content with just accounting for key tries.\n",
    "\n",
    "In an algorithm, we look also for some countable action that we can use as a measure of run time. In this\n",
    "exercise, we will sort numbers, and we will count the number of comparisons between two numbers. It is\n",
    "pretty certain that to sort we need to compare numbers, and we feel justified in thinking the comparison\n",
    "must take some fixed amount of time, and we are happy letting any other computation be given for free.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "class QueryCompare:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        \n",
    "    def reset_count(self):\n",
    "        self.count = 0\n",
    "        \n",
    "    def compare_gt(self,a,b):\n",
    "        self.count += 1\n",
    "        return a > b\n",
    "\n",
    "    def compare_le(self,a,b):\n",
    "        self.count += 1\n",
    "        return a <= b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise A: Selection Sort. \n",
    "\n",
    "Selection sort is a well known \"slow\" sort. \n",
    "\n",
    "Given an unsorted list of numbers, the algorithm considers the \n",
    "prefix of that list, beginning with the prefix of one element, then two elements, and so on. When it is \n",
    "done considering a prefix, those numbers in the prefix have been placed in order. Therefore when it begins\n",
    "considering a prefix, all numbers but the last are assurdedly in order, and the last might be in order too.\n",
    "Else the last number is moved downwards among the numbers in the list until it finds its place.\n",
    "\n",
    "Just counting comparisons, give a very good formula the predicts ths number of comparison queries made to sort the list, as a function of list size.\n",
    "\n",
    "__To do:__ Experiment to get various runs values for different list lengths $n$. The number of queries is not a strict function of $n$ &mdash; it can vary depending on how the input is arranged. That is a property of the selection sort algorithm. The exact number of queries is data dependent. Then fit a curve to the data. \n",
    "\n",
    "Since we know the result is a quadratic, the curve to fit has the form,\n",
    "$$\n",
    "f(n) = a \\, n^2+b \\,n+c\n",
    "$$\n",
    "optimizing over $a, b$ and $c$.\n",
    "\n",
    "The numpy function numpy.polynomial.polynomial.Polynomial.fit can help.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:\t16,\n",
      "query:\t120,\n",
      "sorted list:\n",
      "[9, 35, 58, 77, 91, 105, 109, 114, 155, 157, 197, 221, 228, 231, 232, 237])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SelectionSort:\n",
    "    \n",
    "    def __init__(self, query_compare_object):\n",
    "        self.qc = query_compare_object\n",
    "\n",
    "    def swap(self,a,i,j):\n",
    "        t = a[i]\n",
    "        a[i] = a[j]\n",
    "        a[j] = t\n",
    "\n",
    "    def sort(self,x):\n",
    "        n = len(x)\n",
    "        self.qc.reset_count()\n",
    "        for i in range(n):\n",
    "            for j in range(i,0,-1):\n",
    "                if self.qc.compare_le(x[j],x[j-1]):\n",
    "                    self.swap(x,j,j-1)\n",
    "        return x\n",
    "    \n",
    "    def test_sort(self,n=16):\n",
    "        test_array = [random.randint(0,n*n) for i in range(n)]\n",
    "        self.sort(test_array)\n",
    "        return (self.qc.count,test_array)\n",
    "\n",
    "ss = SelectionSort(QueryCompare())\n",
    "test = ss.test_sort()\n",
    "print(f'length:\\t{len(test[1])},\\nquery:\\t{test[0]},\\nsorted list:\\n{test[1]})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise B: Merge Sort. \n",
    "\n",
    "Merge sort is a well known \"fast\" sort. \n",
    "\n",
    "Given an unsorted list of numbers, the algorithm breaks the list in two in the middle. It sorts the first\n",
    "half recursively, sorts the second half recursively, then merges back together the two halves. The merge\n",
    "consumes the two sorted half lists to build the sorted combined list by looking at the elements at the top\n",
    "of the halves, removes which is smaller and places that element onto the end of the built list. \n",
    "\n",
    "There will be cases in which all of one half has been consumed yet more remain on the other list, and of course\n",
    "then no choice is made, the element is simplied transferred from the ever dwindleing half list to the ever growing combined list.\n",
    "\n",
    "Just counting comparisons, give a very good formula the predicts ths number of comparison queries made to sort the list, as a function of list size.\n",
    "\n",
    "__To do:__ Experiment to get various runs values for different list lengths $n$. The number of queries will be a strict function of $n$ &mdash; for merge sort, the exact number of queries is _not_ data dependent. Then fit a curve to the data. \n",
    "\n",
    "\n",
    "Since we know the function is $O(n\\,\\log(n))$, the curve to fit has the form,\n",
    "$$\n",
    "f(n) = a \\, \\log n+b \\,n+c\n",
    "$$\n",
    "optimizing over $a, b$ and $c$.\n",
    "\n",
    "\n",
    "The scipy function scipy.optimize.curve_fit can help.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:\t16,\n",
      "query:\t43,\n",
      "sorted list:\n",
      "[7, 30, 34, 39, 41, 58, 95, 96, 156, 159, 166, 167, 179, 198, 201, 214])\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "class MergeSort:\n",
    "    \n",
    "    def __init__(self, query_compare_object):\n",
    "        self.qc = query_compare_object\n",
    "    \n",
    "    def merge(self,x,y):\n",
    "        z = [0]*(len(x)+len(y))\n",
    "        i, j = 0, 0\n",
    "        for k in range(len(z)):\n",
    "            if i>=len(x):\n",
    "                z[k] = y[j]\n",
    "                j += 1\n",
    "                continue\n",
    "            if j>=len(y):\n",
    "                z[k] = x[i]\n",
    "                i += 1\n",
    "                continue\n",
    "            if self.qc.compare_le(x[i],y[j]):\n",
    "                z[k] = x[i]\n",
    "                i += 1\n",
    "            else:\n",
    "                z[k] = y[j]\n",
    "                j += 1\n",
    "        return z\n",
    "            \n",
    "    def sort_aux(self,x):\n",
    "        n = len(x)\n",
    "        if n<2:\n",
    "            return x\n",
    "        x_bot = self.sort_aux(x[:n//2])\n",
    "        x_top = self.sort_aux(x[n//2:])\n",
    "        return self.merge(x_bot,x_top)\n",
    "        \n",
    "    def sort(self,x):\n",
    "        self.qc.reset_count()\n",
    "        return self.sort_aux(x)\n",
    "    \n",
    "    def test_sort(self,n=16):\n",
    "        test_array = self.sort([random.randint(0,n*n) for i in range(n)])\n",
    "        return (self.qc.count,test_array)\n",
    "\n",
    "ms = MergeSort(QueryCompare())\n",
    "test = ms.test_sort()\n",
    "print(f'length:\\t{len(test[1])},\\nquery:\\t{test[0]},\\nsorted list:\\n{test[1]})')\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search and Entropy\n",
    "\n",
    "We are now going to think about how to guess a key, and how to quantify the effort that is expected to guess a key. In the greater context, the security of a protocol is a quote of this difficulty. Since there exists a password, a combination to a safe, or a cut key that opens the lock, it is not possible to say that password system, safe, or lock, is unopenable. Something opens it, and the attacker can discover, one way or the other, the details of what opens it. What we need is to understand and quantify is the difficulties that lie in the way of the attacker's discovery.\n",
    "\n",
    "In code, we will model the key trials as an object QuestionBox which contains a secret, and which can be queried for a True/False answer, about the key. An equality query answers True if the presented key is the secret, and False otherwise. An inequality quere, such as $\\le$, answers True if the presented key is $\\le$ the secret, and False otherwise.\n",
    "\n",
    "For this second sort of query to make sense, we must assume that the keys have an ordering, and less-than is interpreted as a key coming before another in that ordering. They keys might be identified with an integer index, and one key is less than another if its index is less than the other key's index.\n",
    "\n",
    "We will also need probability distributions. These will be represented as objects, that return the probabiity of a key given the key. Or if preferred, rather that the key itself that is presented, it is the index of the key. In this way we can think of keys as being the set of numbers $\\{\\,0,1,\\ldots,n-1\\,\\}$ when in reality they might be various more interesting things &mdash; cuts on a metal bar, combinations for a combination lock, and so on.\n",
    "\n",
    "We look at two probability distributions on elements. Both distributions are on a key set represented by integers 0 through $n-1$. We organize the elements in descending probability. If $p_i$ is the probability of item $i$, the $p_i \\ge p_j$ whenever $i\\le j$.\n",
    "\n",
    "The _truncated geometric distribution_ takes a probability $p_i$ of element $i$ the probability of tossing $i$ heads before the first tail, with a coin of bias $p$. \n",
    "\n",
    "The _single favorite distribution_ sets $p_0 = p$ and the remaining elements 1 through $n-1$ have probabilities each of $(1-p)/(n-1)$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "        \n",
    "class TruncGeometric:\n",
    "    \n",
    "    # implements a PMF with monotonicaly descending probability values\n",
    "    # support in 0 to n-1\n",
    "    \n",
    "    def __init__(self,n,p):\n",
    "        self.n = n\n",
    "        self.p = p\n",
    "        self.c = p*(1-math.pow(p,n))/(1-p)\n",
    "\n",
    "    def p_i(self,i):\n",
    "        return math.pow(self.p,i+1)/self.c\n",
    "\n",
    "\n",
    "class SingleFavorite:\n",
    "        \n",
    "    # implements a PMF with monotonicaly descending probability values\n",
    "    # support in 0 to n-1\n",
    "\n",
    "    def __init__(self,n,p):\n",
    "        self.n = n\n",
    "        self.p = p\n",
    "        self.c = (1.0-p)/(n-1)\n",
    "    \n",
    "    def p_i(self,i):\n",
    "        if i==0:\n",
    "            return self.p\n",
    "        return self.c\n",
    "\n",
    "class QuestionBox:\n",
    "    \n",
    "    def __init__(self,pmf):\n",
    "        self.pmf = pmf\n",
    "        self.secret = 0\n",
    "\n",
    "    def check_normalized(self,pmf):\n",
    "        s = 0\n",
    "        for i in range(pmf.n):\n",
    "            s += pmf.p_i(i)\n",
    "        assert(math.isclose(s,1.0))\n",
    "        \n",
    "    def choose_a_number(self):\n",
    "        r = random.random()\n",
    "        #  between 0 and 1\n",
    "        cumdist = 0.0\n",
    "        for i in range(0,self.pmf.n):\n",
    "            cumdist += self.pmf.p_i(i)\n",
    "            if cumdist >= r:\n",
    "                self.secret = i\n",
    "                return i\n",
    "        return self.pmf.n-1\n",
    "        \n",
    "    def query_equal(self,guess):\n",
    "        return guess == self.secret\n",
    "\n",
    "    def query_le(self,guess):\n",
    "        return guess >= self.secret\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Exercise C: Most Likely First Sequential\n",
    "\n",
    "A typical attack againts a key is to sequentially try all keys until the correct key is found. When a key is chosen, often the choice is made with a bias. Passwords are notorious for being chosen with bias. They are often a birthday or some clever \"secret\" word, like AstroStarDog. We will assume that the attacker has exact knowledge of this bias. Therefore, the impatient attacker should try the likely keys first, as this will speed key discovery.\n",
    "\n",
    "If the keys are $\\{\\,0,1,\\ldots,n-1\\,\\}$, and the probability of key $i$ being chosen is $p_i$, and we arrange the keys so that $p_i \\ge p_j$ when $i<j$, then the attacker acheives expected time,\n",
    "$$\n",
    "\\sum_{i=0}^{n-1} p_i \\, (i+1)\n",
    "$$\n",
    "by asking a equality query on the keys in the order  $,0,1,\\ldots,n-1$. This formula is called the _guessing entropy_.\n",
    "\n",
    "- Complete the code for the guessing entropy function. \n",
    "\n",
    "- Implement the most likely first sequential search and test on the two distributions.\n",
    "\n",
    "- Compare the average number of queries for most likely first search against the guessing entropy.\n",
    "\n",
    "### Exercse D: Binary Search\n",
    "\n",
    "It might be possible that inequality queries are permitted against a key. Such a query can eleminate with a single query many candidates. Although it is not typical that an attacker is permitted such a powerful query, it does happen. (See story below.)\n",
    "\n",
    "In this case the optimal approach is to choose a query that divides the remaining candidates into two equaly halves. With a single query one of the two halves are eliminated. Continuing in this way, in about $\\log n$ queries the key is discovered. \n",
    "\n",
    "- Complete the code for the hartley entropy function ($\\log n$).\n",
    "\n",
    "- Implement the binary search strategy and test on the two distributions.\n",
    "\n",
    "- Compare the average number of queries for binary search against the hartley entropy.\n",
    "\n",
    "### Exercise E: Balanced Search\n",
    "\n",
    "Binary search does not make use of any bias in the key selection. Rather than dividing keys into two equal sets, where equality is by number of keys, try dividing them into two equal sets, where equality is by the sum of the probability of the keys in each part. \n",
    "\n",
    "As the keys are indexed by decreasing likelyhood, this means, for example, that the first query is at location $k$ where $k$ is chosen such that,\n",
    "$$\n",
    "1/2 \\approx \\sum_{i=0}^k p_i\n",
    "$$\n",
    "Subsequent queries are calculated in the same spirit. \n",
    "\n",
    "The result should be likely keys are discovered with fewer queries than unlikely keys. Overall the average number of queries will be the weighted sum, weighted by probability, of what looks like the simple Hartley entropy of log the number of keys at that probability level. That is, \n",
    "$$\n",
    "H(D) = - \\sum_{i=0}^{n-1} p_i \\log p_i\n",
    "$$\n",
    "This is the _Shannon Entropy_. However it is really \"the\" entropy, so it is just called Entropy. With the logarithm in the base 2, the result has dimension of bits.\n",
    "\n",
    "- Complete the code for the shannon entropy function.\n",
    "\n",
    "- Implement the balanced search strategy and test on the two distributions.\n",
    "\n",
    "- Compare the average number of queries for binary search against the shannon entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SearchStrategy:\n",
    "    \n",
    "    def __init__(self,question_box):\n",
    "        self.qb = question_box\n",
    "        self.pmf = question_box.pmf\n",
    "        self.n = question_box.pmf.n\n",
    "\n",
    "    def make_cdf(self,pmf):\n",
    "        cdf = [pmf.p_i(i) for i in range(pmf.n)]\n",
    "        for i in range(1,pmf.n):\n",
    "            cdf[i] += cdf[i-1]\n",
    "        cdf[pmf.n-1] = 1.0 # avoid roundoff problems\n",
    "        return cdf\n",
    "\n",
    "    def shannon_entropy(self):\n",
    "        se = 0\n",
    "        \n",
    "        # code here\n",
    "        \n",
    "        return -se\n",
    "\n",
    "    def guessing_entropy(self):\n",
    "        ge = 0\n",
    "        \n",
    "        # code here \n",
    "\n",
    "        return ge\n",
    "\n",
    "    def hartley_entropy(self):\n",
    "        support = 0\n",
    "        \n",
    "        # code here\n",
    "        \n",
    "        return math.log2(support)\n",
    "\n",
    "    def most_likely_first(self):\n",
    "        # tries values using most likely first strategy and\n",
    "        # question box equality queries until the secret is\n",
    "        # discovered.\n",
    "        \n",
    "        # code here\n",
    "        \n",
    "        return False\n",
    "\n",
    "    def most_likely_first_avg(self,trials=1000):\n",
    "        tot_queries = 0\n",
    "        for i in range(trials):\n",
    "            magic = self.qb.choose_a_number()\n",
    "            (m,t) = self.domain_sweep()\n",
    "            tot_queries += t\n",
    "            assert (m==magic)\n",
    "        return tot_queries/trials\n",
    "    \n",
    "    def binary_search(self):\n",
    "        # tries values using binary search and question\n",
    "        # box inequality queries until the secret is \n",
    "        # discovered\n",
    "        \n",
    "        # code here \n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def binary_search_avg(self,trials=1000):\n",
    "        tot_queries = 0\n",
    "        for i in range(trials):\n",
    "            magic = self.qb.choose_a_number()\n",
    "            (m,t) = self.binary_search()\n",
    "            tot_queries += t\n",
    "            assert (magic==m)\n",
    "        return tot_queries/trials\n",
    "\n",
    "    def balanced_search(self):\n",
    "        # tries values using balanced search and question\n",
    "        # box inequality queries until the secret is \n",
    "        # discovered\n",
    "        \n",
    "        # code here\n",
    "        \n",
    "        return False\n",
    "            \n",
    "    def balanced_search_avg(self,trials=1000):\n",
    "        tot_queries = 0\n",
    "        for i in range(trials):\n",
    "            magic_number = self.qb.choose_a_number()\n",
    "            #print(f'magic number: {magic_number}')\n",
    "            (mn,nq) = self.balanced_search()\n",
    "            assert(mn==magic_number)\n",
    "            tot_queries += nq\n",
    "        return tot_queries/trials            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "truncated geometric distribution. n=64 and prob=0.7\n",
      "\tlog n: 4.159,\tbinary search queries: 5.915\n",
      "\tguessing entropy: 3.333,\tmost likely first queries: 3.380\n",
      "\tshannon entropy: 2.938,\tbalanced search queries: 3.261\n",
      "\n",
      "single favorite distribution. n=64 and prob=0.7\n",
      "\tlog n: 4.159,\tbinary search queries: 6.476\n",
      "\tguessing entropy: 10.600,\tmost likely first queries: 11.046\n",
      "\tshannon entropy: 2.674,\tbalanced search queries: 2.748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = 64\n",
    "p = 0.7\n",
    "print(f'\\ntruncated geometric distribution. n={n} and prob={p}')\n",
    "ss = SearchStrategy(QuestionBox(TruncGeometric(n,p)))\n",
    "print(f'\\tlog n: {math.log(n):.3f},\\tbinary search queries: {ss.binary_search_avg()}')\n",
    "print(f'\\tguessing entropy: {ss.guessing_entropy():.3f},\\tmost likely first queries: {ss.domain_sweep_avg():.3f}')\n",
    "print(f'\\tshannon entropy: {ss.shannon_entropy():.3f},\\tbalanced search queries: {ss.balanced_search_avg():.3f}')\n",
    "\n",
    "\n",
    "n = 64\n",
    "p = 0.7\n",
    "print(f'\\nsingle favorite distribution. n={n} and prob={p}')\n",
    "ss = SearchStrategy(QuestionBox(SingleFavorite(n,p)))\n",
    "print(f'\\tlog n: {math.log(n):.3f},\\tbinary search queries: {ss.binary_search_avg()}')\n",
    "print(f'\\tguessing entropy: {ss.guessing_entropy():.3f},\\tmost likely first queries: {ss.domain_sweep_avg():.3f}')\n",
    "print(f'\\tshannon entropy: {ss.shannon_entropy():.3f},\\tbalanced search queries: {ss.balanced_search_avg():.3f}')\n",
    "\n",
    "#print(f'cumulative distribution function: {ss.pmf.get_cdf()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "sample output of the exercises\n",
    "\n",
    "truncated geometric distribution. n=64 and prob=0.7\n",
    "\tlog n: 4.159,\tbinary search queries: 5.915\n",
    "\tguessing entropy: 3.333,\tmost likely first queries: 3.380\n",
    "\tshannon entropy: 2.938,\tbalanced search queries: 3.261\n",
    "\n",
    "single favorite distribution. n=64 and prob=0.7\n",
    "\tlog n: 4.159,\tbinary search queries: 6.476\n",
    "\tguessing entropy: 10.600,\tmost likely first queries: 11.046\n",
    "\tshannon entropy: 2.674,\tbalanced search queries: 2.748\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epilogue: A True Story\n",
    "\n",
    "How useful is the knowledge presented in this exercise? A true story ...\n",
    "\n",
    "At some private university in South Florida that had a directory service allowing data lookup. Although you could do a lookup on social security number, if you knew it, only the last 4 digits were ever presented, so the remaining 5 digits were considered securely secret. \n",
    "\n",
    "The designers apparantly were thinking along the lines of Guessing Entropy and equality queries. This would give an entropy as high as $10^5/2$, about a quarter of a million queries.\n",
    "\n",
    "However, it was overlooked was that \"prefix search\" on social security numbers was permited. While not exactly an inequality query, the differences are unimportant in effect. \n",
    "\n",
    "How would you use the principles of binary search and inequality queries to lower the expected number of queries to discover a particular social security number from the believed quarter of a million queries, to only 25 queries?\n",
    "\n",
    "The flaw was reported and patched.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
